<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <link rel="icon" href="data:;base64,iVBORw0KGgo=">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" href="static/style.css" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Generalizable Sparse-View 3D Reconstruction from Unconstrained Images</title>
    <meta name="description" content="Generalizable Sparse-View 3D Reconstruction from Unconstrained Images paper. Official web with qualitative comparisons, links to the source code, and additional materials.">
    <meta name="keywords" content="genwildsplat,3dgs,nerf,official,code" />
    <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700&display=swap" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/@tabler/icons-webfont@3.7.0/dist/tabler-icons.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  </head>

  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="hero-container">

          <h1 class="publication-title">
            <strong class="title-gradient">GenWildSplat</strong><br>
            <span class="publication-subtitle">Generalizable Sparse-View 3D Reconstruction from Unconstrained Images</span>
          </h1>

          <div class="publication-authors">
            <span class="author-block"><a href="https://vinayak-vg.github.io/">Vinayak Gupta</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><a href="https://chih-hao-lin.github.io/">Chih-Hao Lin</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><a href="https://anandbhattad.github.io/">Anand Bhattad</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a></span>
          </div>

          <div class="conference-row"><strong>CVPR 2026</strong></div>

          <div class="publication-links">
            <span class="link-block">
              <a href="https://genwildsplat.github.io" class="external-link button">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                <span>Paper</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://genwildsplat.github.io/" class="external-link button">
                <span class="icon"><i class="fas fa-globe"></i></span>
                <span>Project Page</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/genwildsplat/genwildsplat.github.io" target="_blank" class="external-link button">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </span>
          </div>

        </div>
      </div>
    </section>

    <style>
      .video.teaser-video::before {
        padding-bottom: 50%;
      }
    </style>

    <div class="row">
        <div class="col-md-8 offset-md-2">
            <video id="co3d-grid" poster="" width="100%" autoplay loop muted controls playsinline preload="metadata">
                <source src="assets/teaser.mp4" type="video/mp4">
            </video>
        </div>
    </div>

    <div class="row">
    <div class="col-md-8 offset-md-2 rounded"
        style="text-align: center; padding: 5px 0; background-color: #d0d5ec;">
        <h6 style="margin: 0; font-size: 18px; color: rgb(0,0,0);">
            <strong>TL;DR</strong>: Feed-forward in-the-wild scene reconstruction from sparse views in 3s on a A6000 GPU.
        </h6>
        </div>
    </div>
<section style="margin: 2rem 0;">
    <div style="max-width: 900px; margin: 0 auto; text-align: center; padding: 15px 20px; background-color: #f0f0f8; border-radius: 8px; border: 1px solid #dcdcdc;">
        <p style="margin: 0; font-size: 1.1em; color: #333; font-weight: 600;">
            Note: All video results are presented on real-world scenes that were not seen during training!
        </p>
        <!-- <p style="margin: 0.5em 0 0 0; font-size: 1.1em; color: #333; font-weight: 600;">
            (Tip: Zoom out in your browser for the best experience when viewing the comparisons.)
        </p> -->
    </div>
</section>

  <section class="comparison-grid-sota">
    <h2>Video Comparison Against State-of-the-Art Methods</h2>

    <p style="text-align:justify;max-width:920px;margin:1.0rem auto;color:#000000;">
      Each row shows the input view, reconstructions from WildGaussians and NexusSplats, and our GenWildSplat result. Under sparse inputs and varied lighting, our method yields more consistent novel views.
    </p>
    
    <div id="grid-container">
      <div class="comparison-grid" data-columns="4">
        
        <div class="row" data-row-id="1" style="display: none;">
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/Oidor_Chapel_Alcala_de_Henares.mp4">Input</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/oidor_wg_1.mp4">WildGaussians</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/oidor_ns_1.mp4">NexusSplats</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/rgb_ours.mp4">GenWildSplat (Ours)</div>
        </div>  
        
        <div class="row" data-row-id="2">
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/Palacio_de_Viana_Cordoba.mp4">Input</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/viana_wg.mp4">WildGaussians</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/viana_ns.mp4">NexusSplats</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/viana_ours.mp4">GenWildSplat (Ours)</div>
        </div>

        <div class="row" data-row-id="3">
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/Our_Lady_of_Sorrows_church_in_Rybnik_above_ground.mp4">Input</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/lady_wg.mp4">WildGaussians</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/lady_ns.mp4">NexusSplats</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/lady_ours.mp4">GenWildSplat (Ours)</div>
        </div>

        <div class="row" data-row-id="4">
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/Old_Synagogue_in_Tarnow.mp4">Input</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/tarnow_wg.mp4">WildGaussians</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/tarnow_ns.mp4">NexusSplats</div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/tarnow_ours.mp4">GenWildSplat (Ours)</div>
        </div>
        
        <div class="row" data-row-id="5" style="display: none;">
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/Olisov_Palace.mp4"></div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/olisov_wg.mp4"></div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/olisov_ns.mp4"></div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/olisov_ours.mp4"></div>
        </div>

        <div class="row" data-row-id="6" style="display: none;">
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/Palacio_Episcopal_de_Malaga.mp4"></div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/palacio_wg.mp4"></div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/palacio_ns.mp4"></div>
          <div class="cell" data-type="video" data-src="assets/comparison_sota_videos/palacio_ours.mp4"></div>
        </div>  
      </div>
    </div>
    
    <div class="navigation-controls" style="text-align: center; margin-top: 20px;">
      <button id="prev-button" disabled>Previous</button>
      <span id="page-info">1 / 6</span>
      <button id="next-button">Next</button>
    </div>
  </section>

<!-- <section class="g5-section">
  <div class="g5-text-content">
    <h2>Video Comparison Against Feed-Forward Methods</h2>
    <p>
Each row presents the input view, target lighting image, reconstructions from AnySplat+Style Transfer (ST) and AnySplat+DiffusionRenderer (DR), and our GenWildSplat result. Baselines were evaluated under similar computational settings and therefore, DiffusionRenderer could not be run on longer video sequences leading to view-inconsistency. However, DiffusionRenderer still outputs simply darken daytime images to approximate the target night condition, resulting in inaccurate renderings.    </p>
  </div>

  <div class="g5-container">
    <div class="g5-header-row">
      <div class="g5-header-item">Input View</div>
      <div class="g5-header-item">Target Style</div>
      <div class="g5-header-item">AnySplat + ST</div>
      <div class="g5-header-item">AnySplat + DR</div>
      <div class="g5-header-item">GenWildSplat (Ours)</div>
    </div>

    <div class="g5-content-row">
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/oidor.mp4"></video>
      </div>
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/oidor_style.mp4"></video>
      </div>
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/oidor_ccpl.mp4"></video>
      </div>
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/oidor_dr.mp4"></video>
      </div>
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/oidor_ours.mp4"></video>
      </div>
    </div>

    <div class="g5-content-row">
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/tarnow.mp4"></video>
      </div>
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/tarnow_style.mp4"></video>
      </div>
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/tarnow_ccpl.mp4"></video>
      </div>
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/tarnow_dr.mp4"></video>
      </div>
      <div class="g5-cell">
        <video loop muted playsinline autoplay src="assets/feed_forward/tarnow_ours.mp4"></video>
      </div>
    </div>
  </div>
</section> -->

  <section>
  <h2>Side-by-Side Comparison of Appearance Modeling</h2>

  <p style="text-align:center;max-width:920px;margin:0.4rem auto;color:#000000;">
  Each left-right pair compares a baseline method with GenWildSplat under identical target views and lighting conditions. </p>

  <div class="depth-row">
    <figure>
      <div class="video-wrapper-depth">
        <video class="video-compare" style="aspect-ratio: 1920/1080" loop muted playsinline>
          <source src="assets/appearance_modelling/combined_wg_tarnow.mp4" type="video/mp4">
        </video>
        <span class="video-label"><span>WildGaussians</span><span>GenWildSplat</span></span>
      </div>
    </figure>

    <figure>
      <div class="video-wrapper-depth">
        <video class="video-compare" style="aspect-ratio: 1920/1080" loop muted playsinline>
          <source src="assets/appearance_modelling/combined_wg_olisov.mp4" type="video/mp4">
        </video>
        <span class="video-label"><span>NexusSplats</span><span>GenWildSplat</span></span>
      </div>
    </figure>
  </div>
</section>

<section style="text-align:center; margin: 30px 0;">
    <h2>Our GenWildSplat Framework</h2>

    <div class="row">
        <div class="col-md-8 offset-md-2">
          <div style="text-align:justify; margin-top: 8px; color:#000000; font-size:0.95rem;">
                Given sparse, unposed images with varying appearance and transient objects, our approach first extracts multi-view features capturing both semantic and geometric information. Dedicated prediction heads estimate depth, camera parameters, and 3D Gaussian attributes, which are then mapped into a canonical 3D representation. A light encoder captures per-image illumination, allowing the model to modulate the Gaussians' colors consistently across views using the appearance adapter. Using a pre-trained segmentation network, transient objects are masked out, and the reconstruction loss focuses on static scene content. This enables photorealistic, view-consistent reconstructions from sparse, in-the-wild images.
            </div>
            <video id="co3d-grid" 
                   poster="" 
                   width="100%" 
                   autoplay 
                   loop 
                   muted 
                   controls 
                   playsinline 
                   preload="metadata"
                   onloadedmetadata="this.playbackRate=0.25; this.defaultPlaybackRate=0.25;">
                <source src="assets/method.mp4" type="video/mp4">
            </video>
            
            
        </div>
    </div>
</section>

<section>
  <h2>Constant Appearance Renderings</h2>
  <p style="text-align:justify;max-width:920px;margin:0.6rem auto;color:#000000;">
    Our method enables rendering a scene under a constant appearance code while preserving full 3D consistency across views - an ability that 2D appearance-transfer or 2D relighting methods typically struggle to maintain.
  </p>

  <div class="crossillum-headers">
    <div class="header-cell">Input</div>
    <div class="header-cell">Appearance #1</div>
    <div class="header-cell">Appearance #2</div>
    <div class="header-cell">Appearance #3</div>
  </div>

  <div class="crossillum-row">
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/Church_of_El_Salvador_Ubeda_1_same.mp4" type="video/mp4">
      </video>
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/church1.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/same_scene_diff_app/church1.jpg" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/church2.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/same_scene_diff_app/church2.jpg" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/church3.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/same_scene_diff_app/church3.jpg" />
    </div>
  </div>

  <div class="crossillum-row">
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/Castello_di_Fenis_2.mp4" type="video/mp4">
      </video>
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/fenis1.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/same_scene_diff_app/fenis1.jpg" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/fenos2.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/same_scene_diff_app/fenis2.jpg" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/fenis3.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/same_scene_diff_app/fenis3.jpg" />
    </div>
  </div>

  <div class="crossillum-row">
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/Castello_dellImperatore_2.mp4" type="video/mp4">
      </video>
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/castello1.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/same_scene_diff_app/castello1.jpg" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/castello2.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/same_scene_diff_app/castello2.jpg" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/same_scene_diff_app/castello3.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/same_scene_diff_app/castell3.jpg" />
    </div>
  </div>
</section>

<section class="diff-view-sota">
    <h2 style="text-align:center;">Flexible Viewpoint and Appearance Control</h2>
    <p style="text-align:justify;max-width:920px;margin:0.4rem auto;color:#000000;">
      Our method supports flexible appearance change and free-viewpoint rendering from a 3D scene representation. The results demonstrate the model's ability to preserve geometric consistency while generating novel combinations of viewpoints and illumination conditions.
    </p>
    
    <div class="grid-container" style="max-width:1200px;margin:18px auto;">
      <div class="diff-view-header">
        <div class="diff-view-header-cell">Input View</div>
        <div class="diff-view-header-cell">Same View<span class="header-line-break"></span> Different Lighting</div>
        <div class="diff-view-header-cell">Different View<span class="header-line-break"></span> Same Lighting</div>
        <div class="diff-view-header-cell">Different View<span class="header-line-break"></span> Different Lighting</div>
      </div>

      <div class="diff-view-grid">
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/St_Marks_Church_Zagreb_2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/stmark_sameview.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/stmark_separate.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/stmark_inter.mp4" type="video/mp4">
          </video>
        </div>

        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/St_Nicholas_Cathedral_Kyiv_2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/stnicho_sameview.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/stnicho_separate.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/stnicho_interpolate.mp4" type="video/mp4">
          </video>
        </div>

        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/Surb_Karapet_Church_Noravank_monastery_3.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/surb_sameview.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/surb_separate.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/diff_view_diff_app/surb_interpolate.mp4" type="video/mp4">
          </video>
        </div>

      </div>
    </div>
</section>

<style>
  .diff-view-header, .diff-view-grid {
    display: grid;
    grid-template-columns: repeat(4, 1fr);
    gap: 10px;
    align-items: start;
    margin: 0 auto;
    max-width: 1200px;
    padding: 0 10px; 
  }
  .header-line-break {
      display: block; 
  }
  .diff-view-header {
    margin-bottom: 10px;
  }
  .diff-view-header-cell {
    text-align: center;
    font-weight: bold;
    padding: 5px;
    font-size: 1.1em;
  }
  .cell-diff-view {
    position: relative;
    width: 100%;
    aspect-ratio: 1 / 1;
    overflow: hidden;
    border-radius: 8px;
    background: #111;
    box-shadow: 0 4px 8px rgba(0,0,0,0.15);
  }
  .cell-diff-view video {
    width: 100%;
    height: 100%;
    object-fit: cover;
    display: block;
  }
  @media (max-width: 1000px) {
    .diff-view-header, .diff-view-grid {
      grid-template-columns: repeat(2, 1fr);
    }
  }
  @media (max-width: 600px) {
    .diff-view-header, .diff-view-grid {
      grid-template-columns: 1fr;
    }
  }
</style>

<section>
  <h2>Cross-Scene Illumination Transfer</h2>
  <p style="text-align:justify;max-width:920px;margin:1.0rem auto;color:#000000;">
    GenWildSplat can transfer lighting or appearance from one scene to another, enabling controlled appearance changes while preserving geometry. Such appearance transfer is not feasible with prior methods like WildGaussians and NexusSplats, which couple appearance and geometry optimization.
  </p>  

  <div class="crossillum-row">
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/cross_scene/Basilica_of_San_Vicente_Avila_2.mp4" type="video/mp4">
      </video>
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/cross_scene/scene1_target_1.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/cross_scene/target_1.png" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/cross_scene/scene_1_target_2.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/cross_scene/target_3.png" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/cross_scene/scene_1_target_3.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/cross_scene/target_2.png" />
    </div>
  </div>

  <div class="crossillum-row">
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/cross_scene/Church_of_John_the_Baptist_Kerch_2.mp4" type="video/mp4">
      </video>
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/cross_scene/scene_3_target_2.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/cross_scene/scene_2_target_1.png" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/cross_scene/scene_3_target_1.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/cross_scene/scene_2_target_2.png" />
    </div>
    <div class="cell">
      <video loop muted autoplay playsinline preload="none">
        <source src="assets/cross_scene/scene_3_target_3.mp4" type="video/mp4">
      </video>
      <img class="overlay" src="assets/cross_scene/scene_2_target_3.png" />
    </div>
  </div>
</section>

<section id="views-gallery">
  <h1 class="section-title">Video Results across Varying Input View Count</h1>
  <h2 id="views-heading">2 Input Views</h2>
  
  <p style="text-align:justify;max-width:920px;margin:0.4rem auto;color:#000000;">
    Example reconstructions from varying numbers of input views. Use the controls below to browse results for 2-6 input images. This illustrates that reconstruction quality improves with more views, while GenWildSplat remains robust even with only two inputs. Experiments are limited to six views due to computational constraints, though the method can handle more in practice.
  </p>
  
  <div class="views-controls">
    <button id="views-prev">Prev</button>
    <button id="views-next">Next</button>
  </div>

  <div id="views-grid" class="views-grid"></div>

  <div id="views-templates" style="display:none;">
    <div class="views-set" data-views="2">
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/2views/Ancient.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/2views/Ancient.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/2views/image.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/2views/font.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/2views/image copy.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/2views/franz.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/2views/image copy 2.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/2views/fraue.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="views-set" data-views="3">
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/3views/Sun.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/3views/SunTemple.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/3views/Surb.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/3views/Surb.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/3views/image.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/3views/fushimi.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/3views/donjon.jpg" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/3views/Donjon.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="views-set" data-views="4">
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/4views/plast.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/4views/Plastovy.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/4views/pont.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/4views/Pont.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/4views/villa.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/4views/villa.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/4views/image.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/4views/castle.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="views-set" data-views="5">
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/5views/image.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/5views/Vyoso.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/5views/image copy.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/5views/West.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/5views/image copy 2.png " alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/5views/white.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/5views/image copy 3.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/5views/Urqu.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="views-set" data-views="6">
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/6views/Ugra.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/6views/Ugra_Narasimha_Temple_statue_3.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/6views/Tsir.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/6views/Tsiranavor_church_of_Avan_1.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/6views/Town_Hall.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/6views/Town_hall_in_Zamosc_2.mp4" type="video/mp4">
        </video>
      </div>
      <div class="cell">
        <img class="thumb" src="assets/varying_nviews/6views/Upper.png" alt="">
        <video playsinline muted loop preload="metadata">
          <source src="assets/varying_nviews/6views/Upper_Basilica_in_Assisi_2.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<style>
#views-gallery { margin:2rem 0; }
#views-gallery h2 { text-align:center; font-size:2rem; margin-bottom:1rem; font-weight:700; }
.views-controls { display:flex; justify-content:center; gap:12px; margin-bottom:1rem; }
.views-controls button { padding:0.4rem 0.8rem; font-weight:700; cursor:pointer; }

.views-grid { display:grid; grid-template-columns: repeat(4, 1fr); gap:16px; justify-items:center; align-items:start; }
.views-set { display:none; }
.views-set.active { display:contents; }

.cell { position: relative; width:100%; max-width:280px; aspect-ratio:1/1; overflow:hidden; border-radius:8px; background:#111; }
.cell video { position:absolute; inset:0; width:100%; height:100%; object-fit:cover; display:block; }
.cell .thumb { position:absolute; top:6px; left:6px; width:64px; height:64px; object-fit:cover; border-radius:6px; border:2px solid white; z-index:4; }
.section-title {
  text-align: center;
  font-size: 2rem;
  font-weight: 700;
  margin-bottom: 0.5rem;
}

#views-heading {
  text-align: center;
  font-size: 1.5rem;
  font-weight: 600;
  margin-bottom: 1rem;
}

@media(max-width:1100px){ .views-grid{grid-template-columns:repeat(2,1fr);} .cell{max-width:44vw;} }
@media(max-width:480px){ .views-grid{grid-template-columns:1fr;} .cell{max-width:92vw;} }
</style>

<script>
const templateSets = Array.from(document.querySelectorAll('#views-templates .views-set'));
const viewsGrid = document.getElementById('views-grid');
const titleEl = document.getElementById('views-heading');
const nextBtn = document.getElementById('views-next');
const prevBtn = document.getElementById('views-prev');
let idx = 0;

// Optimized showSet using the global shared observer from scripts.js
function showSet(i){
  const set = templateSets[i];
  viewsGrid.innerHTML = set.innerHTML;
  titleEl.textContent = `${set.dataset.views} Input Views`;
  
  const vids = viewsGrid.querySelectorAll('video');
  vids.forEach(v => {
    // Register with the global efficient observer
    if(window.sharedVideoObserver) {
        window.sharedVideoObserver.observe(v);
    } else {
        // Fallback if scripts.js hasn't loaded yet (unlikely)
        v.play().catch(()=>{});
    }
  });
}

nextBtn.onclick = ()=>{ idx=(idx+1)%templateSets.length; showSet(idx); };
prevBtn.onclick = ()=>{ idx=(idx-1+templateSets.length)%templateSets.length; showSet(idx); };
showSet(0);
</script>

<style>
  #comparison-grid-section, #comparison-grid-sota, #comparison-grid-feedforward {
    margin: 2rem 0;
  }

  h2 {
    text-align: center;
    font-size: 2rem;
    margin-bottom: 1.5rem;
    font-weight: 700;
  }

  .comparison-grid {
    display: flex;
    flex-direction: column;
    gap: 20px;
    align-items: center;
  }

  .comparison-grid .grid-header {
    display: grid;
    gap: 12px;
    width: 100%;
    margin-bottom: 10px;
    justify-items: center;
    align-items: center;
  }

  .comparison-grid .grid-header .col-title {
    font-weight: 700;
    font-size: 0.95rem;
    color: #111;
    background: rgba(255,255,255,0.92);
    padding: 6px 8px;
    border-radius: 6px;
    box-shadow: 0 2px 6px rgba(0,0,0,0.08);
    width: 100%;
    text-align: center;
  }

  .comparison-grid .cell::after {
    display: none;
  }

  .comparison-grid[data-columns="4"] .grid-header {
    grid-template-columns: repeat(4, 1fr);
  }
  .comparison-grid[data-columns="5"] .grid-header {
    grid-template-columns: repeat(5, 1fr);
  }

  .comparison-grid .row {
    display: grid;
    gap: 12px;
    justify-items: center;
    width: 100%;
  }

  .comparison-grid[data-columns="4"] .row {
    grid-template-columns: repeat(4, 1fr);
  }
  .comparison-grid[data-columns="5"] .row {
    grid-template-columns: repeat(5, 1fr);
  }

  .comparison-grid .cell {
    position: relative;
    width: 100%;
    aspect-ratio: 1 / 1;
    background: #111;
    border-radius: 8px;
    overflow: hidden;
    cursor: default;
    box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    transition: transform 0.18s, box-shadow 0.18s;
  }

  .comparison-grid .cell:hover {
    transform: scale(1.02);
    box-shadow: 0 8px 20px rgba(0,0,0,0.22);
  }

  .comparison-grid .cell video,
  .comparison-grid .cell img {
    position: absolute;
    inset: 0;
    width: 100%;
    height: 100%;
    object-fit: cover;
    border-radius: 8px;
    display: block;
  }

  @media (max-width: 1000px) {
    .comparison-grid[data-columns="4"] .row,
    .comparison-grid[data-columns="4"] .grid-header {
      grid-template-columns: repeat(2, 1fr);
    }
    .comparison-grid[data-columns="5"] .row,
    .comparison-grid[data-columns="5"] .grid-header {
      grid-template-columns: repeat(2, 1fr);
    }
  }

  @media (max-width: 600px) {
    .comparison-grid .row,
    .comparison-grid .grid-header {
      grid-template-columns: 1fr;
    }
  }
</style>

<script>
  const grids = Array.from(document.querySelectorAll('.comparison-grid'));

  grids.forEach(grid => {
    const firstRow = grid.querySelector('.row');
    const colCount = grid.dataset.columns ? parseInt(grid.dataset.columns, 10) : null;

    if (firstRow) {
      const titles = Array.from(firstRow.children).map(c => (c.textContent || '').trim());

      if (!grid.querySelector('.grid-header')) {
        const header = document.createElement('div');
        header.className = 'grid-header';

        if (colCount === 4) header.style.gridTemplateColumns = 'repeat(4, 1fr)';
        else if (colCount === 5) header.style.gridTemplateColumns = 'repeat(5, 1fr)';

        for (let i = 0; i < (colCount || titles.length); ++i) {
          const t = document.createElement('div');
          t.className = 'col-title';
          t.textContent = titles[i] || '';
          header.appendChild(t);
        }

        grid.insertBefore(header, grid.firstChild);
      }
    }

    const cells = Array.from(grid.querySelectorAll('.cell'));
    cells.forEach(c => { c.textContent = ''; });

    cells.forEach(cell => {
      const type = cell.dataset.type;
      const src = cell.dataset.src;
      if (!src) return;

      if (type === 'img') {
        const img = document.createElement('img');
        img.src = src;
        img.loading = 'lazy';
        img.alt = '';
        cell.appendChild(img);
      } else if (type === 'video') {
        const vid = document.createElement('video');
        vid.src = src;
        vid.autoplay = false; // Handled by observer now
        vid.muted = true;
        vid.loop = true;
        vid.playsInline = true;
        vid.preload = "none"; // Important for performance
        cell.appendChild(vid);
        
        // Register with global observer
        if(window.sharedVideoObserver) {
            window.sharedVideoObserver.observe(vid);
        }
      }
    });
  });
</script>

    <!-- <section class="diff-view-sota">
    <h2 style="text-align:center;">Effect of number of views</h2>
    
    <p style="text-align:justify;max-width:920px;margin:0.4rem auto;color:#000000;"> 
      The results show that 3D reconstruction quality directly correlates with input view count. Increasing context views (2 to 6) significantly enhances novel-view synthesis. Low-view input (1-3 views) leads to geometric holes and artifacts, while a higher number of views (5-6 views) yields a more robust, hole-free reconstruction.
    </p>
    <div class="grid-container" style="max-width:1200px;margin:18px auto;">
      
      <div class="num-views-header">
        <div class="diff-view-header-cell">1 View</div>
        <div class="diff-view-header-cell">2 Views</div>
        <div class="diff-view-header-cell">3 Views</div>
        <div class="diff-view-header-cell">4 Views</div>
        <div class="diff-view-header-cell">5 Views</div>
        <div class="diff-view-header-cell">6 Views</div>
      </div>

      <div class="num-views-grid">
        
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/amphi_1.mp4" type="video/mp4">
          </video>
        </div>

        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/amphi_2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/amphi_3.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/amphi_4.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/amphi_5.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/amphi_6.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/ancient_1.mp4" type="video/mp4">
          </video>
        </div>

        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/ancient_2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/ancient_3.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/ancient_4.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/ancient_5.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/ancient_6.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/roman_1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/roman_2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/roman_3.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/roman_4.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/roman_5.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/num_views/roman_6.mp4" type="video/mp4">
          </video>
        </div>

      </div>
    </div>
</section> -->

<section class="diff-view-sota">
    <h2 style="text-align:center;">Effect of Input View Count on Scene Reconstruction</h2>
    
    <p style="text-align:justify;max-width:920px;margin:0.4rem auto;color:#000000;"> 
      The results show that 3D reconstruction quality directly correlates with input view count. Increasing context views (2 to 6) significantly enhances novel-view synthesis. Low-view input (1-3 views) leads to geometric holes and artifacts, while a higher number of views (5-6 views) yields a more robust, hole-free reconstruction.
    </p>

    <div class="merged-video-container">
      
      <div class="merged-header">
        <div>1 View</div>
        <div>2 Views</div>
        <div>3 Views</div>
        <div>4 Views</div>
        <div>5 Views</div>
        <div>6 Views</div>
      </div>

      <div class="merged-row">
        <video autoplay loop muted playsinline preload="metadata">
            <source src="assets/num_views/merged/amphi_combined.mp4" type="video/mp4">
        </video>
      </div>

      <div class="merged-row">
        <video autoplay loop muted playsinline preload="metadata">
            <source src="assets/num_views/merged/ancient_combined.mp4" type="video/mp4">
        </video>
      </div>

      <div class="merged-row">
        <video autoplay loop muted playsinline preload="metadata">
            <source src="assets/num_views/merged/roman_combined.mp4" type="video/mp4">
        </video>
      </div>

    </div>
</section>

<style>
  /* Container settings */
  .merged-video-container {
    max-width: 1200px;
    margin: 2rem auto;
    padding: 0 10px;
  }

  /* Header Styling */
  .merged-header {
    display: grid;
    grid-template-columns: repeat(6, 1fr); /* EXACTLY 6 columns to match video content */
    text-align: center;
    font-weight: bold;
    margin-bottom: 5px;
    font-size: 1.1em;
  }

  /* Video Styling */
  .merged-row {
    margin-bottom: 15px; /* Space between the long video strips */
    border-radius: 8px;
    overflow: hidden;
    box-shadow: 0 4px 10px rgba(0,0,0,0.1);
  }

  .merged-row video {
    width: 100%;
    display: block;
  }

  /* Mobile Responsiveness */
  /* Because the video is very wide, on phones the columns might look too small.
     We keep it 100% width, but you could allow scrolling if preferred. */
  @media (max-width: 768px) {
    .merged-header {
      font-size: 0.8em; /* Shrink text on mobile */
    }
  }
</style>

    <section>
      <h2>Appearance Interpolation</h2>

      <p class="center">
      A slider enables interactive blending between different appearances of the same scene by moving the blue dot along the axis. The resulting smooth transitions demonstrate that our light encoder learns semantically meaningful lighting codes and effectively captures diverse scene appearances.
      </p>

      <video class="video" style="aspect-ratio: 1920/1080;" loop muted playsinline id="appearance-interpolation-video" preload="metadata">
        <source src="assets/interpolate_slides/rgb.mp4" type="video/mp4">
      </video>

      <div style="margin: 0.4rem 10% 6px 10%; margin-left: calc(10% - 13px); margin-right: calc(10% - 10px);">
        <input type="range" min="1" max="100" value="0" step="0.0001" class="slider" 
          data-control-slider-images="slider-bar-1" 
          data-control-video="appearance-interpolation-video" />
      </div>

      <div style="display:flex; justify-content: space-between;" id="slider-bar-1">
        <div class="slider-image" style="--active-weight:100%"><img src="assets/interpolate_slides/1.jpg" /></div>
        <div class="slider-image"><img src="assets/interpolate_slides/2.png" /></div>
        <div class="slider-image"><img src="assets/interpolate_slides/3.png" /></div>
        <div class="slider-image"><img src="assets/interpolate_slides/4.jpg" /></div>
      </div>
    </section>

<script>
(function() {
    var slider = document.querySelector('input[data-control-video="appearance-interpolation-video"]');
    var video = document.getElementById('appearance-interpolation-video');

    if (!slider) return;

    var direction = 1; 
    var speed = 0.3;   
    var isAutoPlaying = true;

    const observer = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
            if(!entry.isIntersecting) isAutoPlaying = false; 
            else isAutoPlaying = true; 
        });
    });
    observer.observe(slider);

    function animate() {
        if (!isAutoPlaying) {
            requestAnimationFrame(animate);
            return;
        }

        var min = parseFloat(slider.min);
        var max = parseFloat(slider.max);
        var current = parseFloat(slider.value);
        var next = current + (speed * direction);

        if (next >= max) {
            next = max;
            direction = -1;
        } else if (next <= min) {
            next = min;
            direction = 1;
        }

        slider.value = next;
        slider.dispatchEvent(new Event('input', { bubbles: true }));
        slider.dispatchEvent(new Event('change', { bubbles: true }));
        requestAnimationFrame(animate);
    }
    requestAnimationFrame(animate);

    var stopEvents = ['mousedown', 'touchstart', 'pointerdown', 'keydown'];
    stopEvents.forEach(function(eventType) {
        slider.addEventListener(eventType, function() {
            isAutoPlaying = false;
          
            observer.disconnect();
        }, { once: true });
    });
})();
</script>

<style>
  #views-effect-section {
    margin: 2rem 0;
  }

  .section-title {
    text-align: center;
    font-size: 2rem;
    font-weight: 700;
    margin-bottom: 1.5rem;
  }

  .views-effect-grid {
    display: grid;
    gap: 12px;
    justify-items: center;
  }

  .grid-header {
    display: grid;
    grid-template-columns: repeat(5, 1fr);
    gap: 12px;
    width: 100%;
    margin-bottom: 10px;
    justify-items: center;
  }

  .col-title {
    font-weight: 700;
    font-size: 0.95rem;
    text-align: center;
  }

  .views-effect-grid .row {
    display: grid;
    grid-template-columns: repeat(5, 1fr);
    gap: 12px;
    width: 100%;
  }

  .views-effect-grid .cell {
    width: 100%;
    max-width: 180px;
    aspect-ratio: 1/1;
    overflow: hidden;
    border-radius: 8px;
    box-shadow: 0 4px 10px rgba(0,0,0,0.15);
  }

  .views-effect-grid .cell img {
    width: 100%;
    height: 100%;
    object-fit: cover;
    display: block;
  }

  @media (max-width: 1000px) {
    .views-effect-grid .row, .grid-header {
      grid-template-columns: repeat(3, 1fr);
    }
  }

  @media (max-width: 600px) {
    .views-effect-grid .row, .grid-header {
      grid-template-columns: repeat(2, 1fr);
    }
  }
</style>

  <section>
  <h2>Depth Prediction</h2>
  <p style="text-align:center;max-width:920px;margin:0.8rem auto;color:#000000;">
        For reference, we show the depth prediction rendered by rasterizing the Gaussians' centers.
  </p>

  <div class="depth-row">
    <figure>
      <div class="video-wrapper-depth">
        <video class="video-compare" style="aspect-ratio: 1920/1080" loop muted playsinline>
          <source src="assets/depth/combined.mp4" type="video/mp4">
        </video>
        <span class="video-label"><span>RGB</span><span>Depth</span></span>
      </div>
    </figure>

    <figure>
      <div class="video-wrapper-depth">
        <video class="video-compare" style="aspect-ratio: 1920/1080" loop muted playsinline>
          <source src="assets/depth/combined_1.mp4" type="video/mp4">
        </video>
        <span class="video-label"><span>RGB</span><span>Depth</span></span>
      </div>
    </figure>
  </div>
</section>

<section id="views-effect-section" class="megascenes-overview">
  <h1 class="section-title">Curated Scenes from MegaScenes Dataset</h1>
  <p style="text-align:justify;max-width:1000px;margin:0.4rem auto;color:#000000;">
    We showcase a few scenes from our curated set from the MegaScenes dataset used in our evaluations. These outdoor scenes include sparse viewpoints, significant illumination variations, and transient occluders, providing a challenging test of GenWildSplat's generalization capability.</p>
  <div class="views-effect-grid">

    <div class="row">
      <div class="cell">
        <video src="assets/megascenes_overview/National_Theatre_of_Costa_Rica_right.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Novosibirsk_opera_and_ballet_theatre.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Oidor_Chapel_Alcala_de_Henares.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Old_Hunstanton_Lighthouse.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Old_Synagogue_in_Tarnow.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
    </div>

    <div class="row">
      <div class="cell">
        <video src="assets/megascenes_overview/National_Diet_Building.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Olisov_Palace.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Onze-Lieve-Vrouw_Presentatiekerk_Gent.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Opera_Theater_Chelyabinsk.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Osgoode_Hall.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
    </div>

    <div class="row">
      <div class="cell">
        <video src="assets/megascenes_overview/Our_Lady_of_Sorrows_church_in_Rybnik.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Palace_of_the_Banca_Commerciale_Italiana_Milan.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Palacio_de_la_Casa_de_la_Comunidad_de_Teruel.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Palacio_de_Viana_Cordoba.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
      <div class="cell">
        <video src="assets/megascenes_overview/Palacio_Episcopal_de_Malaga.mp4" autoplay loop muted playsinline preload="none"></video>
      </div>
    </div>

  </div>
</section>

<section id="comparison-grid-upperbound">
  <h2>Upper Bound Comparison with Prior Methods</h2>

  <p style="text-align:justify;max-width:920px;margin:1.0rem auto;color:#000000;">
    Prior methods require significantly more views to approach accurate geometry. NexusSplat reaches our performance only at around 216 inputs, whereas GenWildSplat achieves high-quality reconstructions with just 6 views.
  </p>

  <div class="comparison-grid-upperbound">

    <div class="grid-header" style="display:grid; gap:8px; width:100%; margin-bottom:-10px; grid-template-columns: repeat(5, 1fr);">
      <div class="col-title">Input</div>
      <div class="col-title">6 Views</div>
      <div class="col-title">36 Views</div>
      <div class="col-title">216 Views</div>
      <div class="col-title">Ours (6 Views)</div>
    </div>

    <div class="row">
      <div class="cell">
        <img src="assets/upper-bound/image.png" class="media" alt="Input view example 1">
      </div>
      <div class="cell">
        <img src="assets/upper-bound/6/Palace_Entrance.png" class="media" alt="6 views example 1">
      </div>
      <div class="cell">
        <img src="assets/upper-bound/36/Palace_Entrance.png" class="media" alt="36 views example 1">
      </div>
      <div class="cell">
        <img src="assets/upper-bound/216/Palace_Entrance.png" class="media" alt="216 views example 1">
      </div>
      <div class="cell">
        <img src="assets/upper-bound/anysplat/Palace_Entrance.jpg" class="media" alt="Ours (6 views) example 1">
      </div>
    </div>

    <div class="row">
      <div class="cell">
        <img src="assets/upper-bound/image copy.png" class="media" alt="Input view example 2">
      </div>
      <div class="cell">
        <img src="assets/upper-bound/6/India-6634_-_Flickr_-_archer10_(Dennis).png" class="media" alt="6 views example 2">
      </div>
      <div class="cell">
        <img src="assets/upper-bound/36/India-6634_-_Flickr_-_archer10_(Dennis).png" class="media" alt="36 views example 2">
      </div>
      <div class="cell">
        <img src="assets/upper-bound/216/India-6634_-_Flickr_-_archer10_(Dennis).png" class="media" alt="216 views example 2">
      </div>
      <div class="cell">
        <img src="assets/upper-bound/anysplat/India-6634_-_Flickr_-_archer10_(Dennis).jpg" class="media" alt="Ours (6 views) example 2">
      </div>
    </div>

  </div>
</section>


<section>
  <h2>Synthetic Data Generation Pipeline for Curriculum Training</h2>
  <p style="text-align:justify;max-width:920px;margin:1.0rem auto;color:#000000;">
   We train our model in a three-stage fashion with progressively increasing complexity. In Stage I, using only a single scene from the DL3DV dataset, we employ DiffusionRenderer to relight images with diverse, random lighting, generating synthetic data to help the model resolve geometry and appearance ambiguities. Stage II extends this approach to multiple scenes, allowing the model to generalize across scenes and varied appearances. In Stage III, we introduce synthetic occlusions and task the model to remove them, building on the representations learned in the earlier stages.
  </p>
  <img src="assets/synthetic_data_generation.jpg" alt="Synthetic Data Generation" style="max-width:100%; height:auto; display:block; margin:0 auto;">
  
</section>

<!-- <section class="diff-view-sota">
    <h2 style="text-align:center;">Results at each stage of Curriculum Training</h2>
    <p style="text-align:justify;max-width:920px;margin:0.4rem auto;color:#000000;">
        We present video results at each stage of our curriculum training, illustrating progressive improvements in scene reconstruction. After Stage I, the model captures basic appearance variations, such as morning and night (e.g., sky in row 1, column 2), but since trained on a single scene, it generalizes poorly, leading to color shifts. Stage II exposure to multiple scenes improves color consistency and appearance awareness, though transient occlusions remain. Stage III achieves high-quality reconstructions, accurately modeling geometry and effectively removing transient objects.  </p>

    </p>
    
    <div class="grid-container" style="max-width:1200px;margin:18px auto;">
      <div class="diff-view-header">
        <div class="diff-view-header-cell">Input View</div>
        <div class="diff-view-header-cell">After Stage I</div>
        <div class="diff-view-header-cell">After Stage II</div>
        <div class="diff-view-header-cell">After Stage III</div>
      </div>

      <div class="diff-view-grid">
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/curriculum/Fushimi_Inari-taisha.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/curriculum/fushimi_stage1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/curriculum/fushimi_stage2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/curriculum/fushimi_stage3.mp4" type="video/mp4">
          </video>
        </div>

        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/curriculum/Palacio_Episcopal_de_Malaga.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/curriculum/palacio_stage1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/curriculum/palacio_stage2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="cell-diff-view">
          <video autoplay loop muted playsinline preload="none">
            <source src="assets/curriculum/palacio_stage3.mp4" type="video/mp4">
          </video>
        </div>

      </div>
    </div>
</section> -->


    <section>
      <h2>Gallery of Results (100+ Scenes)</h2>
      <p style="text-align:justify;max-width:980px;margin:0.4rem auto;color:#000000;">
        Browse through hundreds of MegaScenes test scenes (never seen by our model during training) reconstructed by GenWildSplat, showcasing its performance across a wide range of outdoor settings.
      </p>

      <div class="controls">
        <button id="prevBtn"> Prev</button>
        <button id="nextBtn">Next </button>
      </div>

      <div id="grid" class="video-grid"></div>
    </section>

  <section id="failure-gallery">
  <h1 class="section-title">Analysis of Failure Cases</h1>
  <h2 id="failure-heading" class="subtitle is-5 has-text-centered">1. Large Motion Changes on Small Objects</h2> 
  
  <p style="text-align:center;max-width:920px;margin:0.4rem auto 1.5rem;color:#000000;">
    These examples illustrate the current limitations of our framework. Use the controls below to navigate through the four discussed failure scenarios.
  </p>
  
  <div class="views-controls has-text-centered">
    <button id="failure-prev">Prev</button>
    <button id="failure-next">Next</button>
  </div>

  <div id="failure-grid" class="failure-grid-container">
    </div>

  <div id="failure-templates" style="display:none;">
    
    <div class="failure-set" data-case="1" data-heading="Large camera motion changes">
      <div class="failure-cell">
        <p class="is-size-5 has-text-weight-bold">Input Video</p>
        <div class="video-placeholder">
          <img class="thumb" src="assets/failure_cases/case1_input_thumb.png" alt="Input frame for small object large motion failure case.">
          <video autoplay playsinline muted loop preload="metadata">
            <source src="assets/failure-case/Bath_Abbey_2_i.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="failure-cell">
        <p class="is-size-5 has-text-weight-bold">Novel View Rendering</p>
        <div class="video-placeholder">
          <img class="thumb" src="assets/failure_cases/case1_output_thumb.png" alt="Output frame showing distortion after editing a small object with large motion."> 
          <video autoplay playsinline muted loop preload="metadata">
            <source src="assets/failure-case/Bath_Abbey_2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="full-width-text">
        <p><strong>Analysis:</strong> When the target/novel view is far away from the input views, the model may struggle to generate a coherent output, leading to visual artifacts and holes.</p>
      </div>
    </div>

    <div class="failure-set" data-case="2" data-heading="Incorrect classification by segmentation model">
      <div class="failure-cell">
        <p class="is-size-5 has-text-weight-bold">Input Video</p>
        <div class="video-placeholder">
          <img class="thumb" src="assets/failure_cases/case2_input_thumb.png" alt="Input frame for liquid dynamics failure case.">
          <video autoplay playsinline muted loop preload="metadata">
            <source src="assets/failure-case/Cathedral_of_Ourense_2_i.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="failure-cell">
        <p class="is-size-5 has-text-weight-bold">Novel View Rendering</p>
        <div class="video-placeholder">
          <img class="thumb" src="assets/failure_cases/case2_output_thumb.png" alt="Output frame failing to correctly synthesize liquid blending.">
          <video autoplay playsinline muted loop preload="metadata">
            <source src="assets/failure-case/Cathedral_of_Ourense_2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="full-width-text">
        <p><strong>Analysis:</strong> The existing segmentation model wrongly classifies statues as transient objects. The most effective solution is to train a new segmentation model that identifies tourists as occlusions while ignoring statues.</p>
      </div>
    </div>

    <div class="failure-set" data-case="3" data-heading="Lighting Inconsistencies">
      <div class="failure-cell">
        <p class="is-size-5 has-text-weight-bold">Input Video</p>
        <div class="video-placeholder">
          <img class="thumb" src="assets/failure_cases/case2_input_thumb.png" alt="Input frame for liquid dynamics failure case.">
          <video autoplay playsinline muted loop preload="metadata">
            <source src="assets/failure-case/Cinderella_Castle_at_Magic_Kingdom_1_i.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="failure-cell">
        <p class="is-size-5 has-text-weight-bold">Novel View Rendering</p>
        <div class="video-placeholder">
          <img class="thumb" src="assets/failure_cases/case2_output_thumb.png" alt="Output frame failing to correctly synthesize liquid blending.">
          <video autoplay playsinline muted loop preload="metadata">
            <source src="assets/failure-case/Cinderella_Castle_at_Magic_Kingdom_1.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="full-width-text">
        <p><strong>Analysis:</strong> In the case of internal lighting in the scene (lighting from the building), the model struggles to accurately disentangle the lighting from the scene and hence the lighting gets baked in. </p>
      </div>
    </div>
    
    <div class="failure-set" data-case="4" data-heading="Double Geometry">
      <div class="failure-cell">
        <p class="is-size-5 has-text-weight-bold">Input Video</p>
        <div class="video-placeholder">
          <img class="thumb" src="assets/failure_cases/case2_input_thumb.png" alt="Input frame for liquid dynamics failure case.">
          <video autoplay playsinline muted loop preload="metadata">
            <source src="assets/failure-case/Chand_Minar_2_i.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="failure-cell">
        <p class="is-size-5 has-text-weight-bold">Novel View Rendering</p>
        <div class="video-placeholder">
          <img class="thumb" src="assets/failure_cases/case2_output_thumb.png" alt="Output frame failing to correctly synthesize liquid blending.">
          <video autoplay playsinline muted loop preload="metadata">
            <source src="assets/failure-case/Chand_Minar_2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="full-width-text">
        <p><strong>Analysis:</strong> In certain cases, our model struggles to accurately predict depth, leading to double geometry artifacts in the rendered output.</p>
      </div>
    </div>
</section>

<section id="related-work" style="margin: -5em auto;">
    <br><br>
    <h2 style="text-align:center;">Related Work</h2>
    <div style="max-width: 800px; margin: 0 auto; padding: 0 10px;">
        <div class="justify" style="padding: -100px 0;">
            
            <p style="font-size: 1.2em; font-weight: 700; margin-top: 1.5em; color: #333;">In-the-wild reconstructions</p>
            <ul>
                <li><a href="https://wild-gaussians.github.io/">WildGaussians: 3D Gaussian Splatting in the Wild</a></li>
                <li><a href="https://nexus-splats.github.io/">NexusSplats: Efficient 3D Gaussian Splatting in the Wild</a></li>
            </ul>

            <p style="font-size: 1.2em; font-weight: 700; margin-top: 1.5em; color: #333;">Appearance/Lighting Transfer Methods</p>
            <ul>
                <li><a href="https://research.nvidia.com/labs/toronto-ai/DiffusionRenderer/">DiffusionRenderer: Neural Inverse and Forward Rendering with Video Diffusion Models</a></li>
                <li><a href="https://github.com/JarrentWu1031/CCPL?tab=readme-ov-file">CCPL: Contrastive Coherence Preserving Loss for Versatile Style Transfer</a></li>
            </ul>
            
            <p style="font-size: 1.2em; font-weight: 700; margin-top: 1.5em; color: #333;">Generalisable Feed-Forward Reconstruction</p>
            <ul>
                <li><a href="https://vgg-t.github.io/">VGGT: Visual Geometry Grounded Transformer</a></li>
                <li><a href="https://city-super.github.io/anysplat/">AnySplat: Feed-forward 3D Gaussian Splatting from Unconstrained Views</a></li>
            </ul>

            <p style="font-size: 1.2em; font-weight: 700; margin-top: 1.5em; color: #333;">Large Scale Outdoor Datasets</p>
            <ul>
                <li><a href="https://megascenes.github.io/">MegaScenes: Scene-Level View Synthesis at Scale</a></li>
            </ul>
        </div>
        
        <!-- <div style='text-align: center; margin-top: 40px; margin-bottom: 20px;'>
            <p>
                <a href="#top" style="text-decoration: none; color: #1772d0; font-weight: 600;">
                    <span class="icon">
                        <i class="ti ti-chevron-up"></i>
                    </span>
                    Back to top
                </a>
            </p>
        </div> -->
    </div>
</section>


<section class="section" id="BibTeX" style="margin-top: 120px;">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{gupta2026genwildsplat,
      title   = {Generalizable Sparse-View 3D Reconstruction from Unconstrained Images},
      author  = {Gupta, Vinayak and Lin, Chih-Hao and Wang, Shenlong and Bhattad, Anand and Huang, Jia-Bin},
      journal = {CVPR},
      year    = {2026}
    }</code></pre>
  </div>
</section>

    <style>
      .controls {
        display: flex;
        justify-content: space-between;
        margin: 1rem 0;
      }
      .video-grid {
        display: grid;
        grid-template-columns: repeat(4, 1fr);
        gap: 15px;
      }
      .cell {
        position: relative;
      }
      .cell video {
        width: 100%;
        border-radius: 6px;
        background: #000;
      }
      .cell img.thumbnail {
        position: absolute;
        top: 0px;
        left: 0px;
        width: 60px;
        height: 60px;
        border-radius: 6px;
        object-fit: cover;
        border: 2px solid white;
        z-index: 4;
        background: #fff;
      }
      section h2 {
        text-align: center;     
        font-size: 2rem;        
        font-weight: 700;      
        margin-bottom: 1rem;    
      }
    </style>

    <script>
      // Optimized Gallery Script
      const TOTAL = 102;      
      const PAGE_SIZE = 12;   
      let page = 0;

      const grid = document.getElementById("grid");

      // Create a single shared observer for the grid items
      const galleryObserver = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const video = entry.target;
            if (!video.src) {
                // Lazy load source
                video.src = video.dataset.src;
                video.play().catch(() => {});
            } else {
                // Resume play
                video.play().catch(() => {});
            }
          } else {
            // Pause when offscreen
            const video = entry.target;
            if(video.src) video.pause();
          }
        });
      }, { threshold: 0.2, rootMargin: "100px" });

      function loadPage() {
        grid.innerHTML = "";

        const start = page * PAGE_SIZE;
        const end = Math.min(start + PAGE_SIZE, TOTAL);

        for (let i = start; i < end; i++) {
          const cell = document.createElement("div");
          cell.className = "cell";

          const img = document.createElement("img");
          img.className = "thumbnail";
          img.loading = "lazy";
          img.src = `assets/renamed_output/images/img_${i}.jpg`;

          const video = document.createElement("video");
          video.muted = true;
          video.loop = true;
          video.autoplay = false; // Handled by observer
          video.playsInline = true;
          video.preload = "none";
          
          // Store src in dataset for lazy loading
          video.dataset.src = `assets/renamed_output/videos/vid_${i}.mp4`;

          // Observe
          galleryObserver.observe(video);

          cell.appendChild(video);
          cell.appendChild(img); 
          grid.appendChild(cell);
        }
      }

      document.getElementById("nextBtn").onclick = () => {
        page = (page + 1) % Math.ceil(TOTAL / PAGE_SIZE);
        loadPage();
      };

      document.getElementById("prevBtn").onclick = () => {
        page = (page - 1 + Math.ceil(TOTAL / PAGE_SIZE)) % Math.ceil(TOTAL / PAGE_SIZE);
        loadPage();
      };

      loadPage();
    </script>

    <script src="static/scripts.js"></script>

  </body>
</html>